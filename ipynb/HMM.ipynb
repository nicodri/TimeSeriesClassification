{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "with h5py.File('../HAR/preprocessed.hdf5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    y_train = np.array(hf.get('y_train'))\n",
    "    s_train = np.array(hf.get('s_train'))\n",
    "    x_test = np.array(hf.get('x_test'))\n",
    "    y_test = np.array(hf.get('y_test'))\n",
    "    s_test = np.array(hf.get('s_test'))\n",
    "    x_train_with_past = np.array(hf.get('x_train_with_past'))\n",
    "    y_train_with_past = np.array(hf.get('y_train_with_past'))\n",
    "    x_test_with_past = np.array(hf.get('x_test_with_past'))\n",
    "    y_test_with_past = np.array(hf.get('y_test_with_past'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 30, 30, 30])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(s_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00833789,  0.99222336,  0.99488295,  0.99715828,  1.00285639,\n",
       "        1.00454112])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(transition_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning a one component Gaussian over all the features\n",
    "def compute_transition(y, alpha=0.1):\n",
    "    '''\n",
    "    Compute the transition matrice.\n",
    "    Rows: states to\n",
    "    cols: states from\n",
    "    States are indexed starting from 1\n",
    "    '''\n",
    "    num_state = np.max(y)\n",
    "    transition = alpha*np.ones((num_state, num_state))\n",
    "    for i in xrange(y.shape[0]-1):\n",
    "        transition[y[i+1]-1, y[i]-1] += 1\n",
    "    # Normalisation (column should be normalized)\n",
    "    transition /= np.sum(transition, axis=0)[:, np.newaxis]\n",
    "    return transition\n",
    "\n",
    "def compute_emission(x, y):\n",
    "    '''\n",
    "    Compute the parameters of the gaussian distribution\n",
    "    of the emission given each state.\n",
    "    We assume each emission distribution is independent,\n",
    "    the covariance matrix is diagonal then.\n",
    "    States are indexed starting from 1\n",
    "    '''\n",
    "    num_state = np.max(y)\n",
    "    \n",
    "    sigma_diag = np.zeros((num_state, x.shape[1]))\n",
    "    mu = np.zeros((num_state, x.shape[1]))\n",
    "    for s in xrange(num_state):\n",
    "        x_s = x[(y == s+1), :]\n",
    "        # Computing mu_s\n",
    "        mu[s] = np.mean(x_s, axis=0)\n",
    "        # Computing sigma_s (by column)\n",
    "        sigma_diag[s] = np.std(x_s, axis=0)\n",
    "\n",
    "    return mu, sigma_diag\n",
    "\n",
    "def compute_logscore(data, log_transition, mu, sigma, C):\n",
    "    y = np.zeros((C, C))\n",
    "    for j in xrange(C):\n",
    "        y[j, :] = np.log(compute_logB(data, mu, sigma_diag, j))\n",
    "\n",
    "    return y + log_transition\n",
    "\n",
    "def compute_logscore_pymc(data, log_transition, means, cov, C):\n",
    "    y = np.zeros((C, C))\n",
    "    for j in xrange(C):\n",
    "        y[j, :] = scipy.stats.multivariate_normal.logpdf(data, mean=means[j], cov=covs[j])\n",
    "    return y + log_transition\n",
    "\n",
    "def viterbi(inputs, init, log_transition, mu, sigma, C):\n",
    "    '''\n",
    "    Evaluates the highest scoring sequence\n",
    "    '''\n",
    "    y = np.zeros((C, C))\n",
    "    initial = np.zeros(C)\n",
    "\n",
    "    initial[init] = 1\n",
    "    initial = np.log(initial)\n",
    "\n",
    "    n = inputs.shape[0]\n",
    "    # To store the maxes\n",
    "    max_table = np.zeros((n, C))\n",
    "    backpointer_table = np.zeros((n, C))\n",
    "\n",
    "    # first timestep\n",
    "    # the initial most likely paths are the initial state distribution\n",
    "    state_init = initial + compute_logscore(inputs[0,:], log_transition, mu, sigma, C)\n",
    "    maxes = np.max(state_init, axis=1)\n",
    "    backpointers = np.argmax(state_init, axis=1)\n",
    "    max_table[0, :] = maxes\n",
    "\n",
    "    for i in xrange(1, n):\n",
    "        # COmputing the score\n",
    "        y = compute_logscore(inputs[i, :], log_transition, mu, sigma, C)\n",
    "        scores = y + np.repeat(maxes.reshape(1, C), C, axis=0)\n",
    "\n",
    "        # compute new maxes\n",
    "        maxes = np.max(scores, axis=1)\n",
    "        backpointers = np.argmax(scores, axis=1)\n",
    "\n",
    "        max_table[i, :] = maxes\n",
    "        backpointer_table[i, :] = backpointers\n",
    "\n",
    "    # follow backpointers to recover max path\n",
    "    classes = np.zeros(n)\n",
    "    classes[n-1] = np.argmax(maxes, axis=0)\n",
    "    for i in xrange(n-1, 0, -1):\n",
    "        classes[i-1] = backpointer_table[i, classes[i]]\n",
    "\n",
    "    return classes\n",
    "\n",
    "def standardize(x):\n",
    "    '''\n",
    "    Standardize each column of x\n",
    "    '''\n",
    "    x_std = np.std(x, axis=0)\n",
    "    x_mu = np.mean(x, axis=0)\n",
    "    \n",
    "    return (x - x_mu)/x_std[np.newaxis, :]\n",
    "\n",
    "def compute_accuracy(pred_classes, true_classes):\n",
    "    '''\n",
    "    Compute accuracy\n",
    "    '''\n",
    "    return np.sum(pred_classes == true_classes) /(1.*len(pred_classes))\n",
    "\n",
    "def compute_logB(data_point, mu, sigma_diag, j):\n",
    "    '''\n",
    "    Compute log(p(x|s_j))\n",
    "    '''\n",
    "    return np.sum([scipy.stats.norm.logpdf(d, loc=mu[j, i], scale=sigma_diag[j, i]) for i, d in enumerate(data_point)])\n",
    "\n",
    "def compute_B(data_point, mu, sigma_diag, j):\n",
    "    '''\n",
    "    Compute p(x|s_j)\n",
    "    '''\n",
    "    return np.prod([scipy.stats.norm.pdf(d, loc=mu[j, i], scale=sigma_diag[j, i]) for i, d in enumerate(data_point)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-inf -inf -inf -inf   0. -inf]\n",
      "[[        -inf         -inf         -inf         -inf -10.65349168\n",
      "          -inf]\n",
      " [        -inf         -inf         -inf         -inf -14.8395688\n",
      "          -inf]\n",
      " [        -inf         -inf         -inf         -inf -12.82739194\n",
      "          -inf]\n",
      " [        -inf         -inf         -inf         -inf  -7.88384383\n",
      "          -inf]\n",
      " [        -inf         -inf         -inf         -inf  -0.84924053\n",
      "          -inf]\n",
      " [        -inf         -inf         -inf         -inf -20.8956498\n",
      "          -inf]]\n",
      "[-10.65349168 -14.8395688  -12.82739194  -7.88384383  -0.84924053\n",
      " -20.8956498 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:7: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "C=6\n",
    "init = 4\n",
    "y = np.zeros((C, C))\n",
    "initial = np.zeros(C)\n",
    "\n",
    "initial[init] = 1\n",
    "initial = np.log(initial)\n",
    "print(initial)\n",
    "\n",
    "state_init = initial + compute_logscore(x_standard[0,:], log_transition_train, mu, sigma_diag, C)\n",
    "print(state_init)\n",
    "print(np.max(state_init, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Sequence Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample + MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 6)\n"
     ]
    }
   ],
   "source": [
    "# We retain 6 features (known to be independent)\n",
    "\n",
    "x = np.concatenate((x_train[:, :3], x_train[:, 41:44]), axis=1)\n",
    "x_sub_test = np.concatenate((x_test[:, :3], x_test[:, 41:44]), axis=1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 6)\n",
      "(6, 6)\n",
      "(6, 6)\n",
      "(6, 6)\n"
     ]
    }
   ],
   "source": [
    "# Learning the HMM\n",
    "\n",
    "# standardization\n",
    "x_standard = standardize(x)\n",
    "print(x_standard.shape)\n",
    "\n",
    "# ### TRANSITION\n",
    "transition_train = compute_transition(y_train)\n",
    "log_transition_train = np.log(transition_train)\n",
    "print(transition_train.shape)\n",
    "\n",
    "# ### EMISSION\n",
    "mu, sigma_diag = compute_emission(x_standard, y_train)\n",
    "print(mu.shape)\n",
    "print(sigma_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:41: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY train: 0.876666666667\n",
      "CPU times: user 7.27 s, sys: 67.8 ms, total: 7.34 s\n",
      "Wall time: 7.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sequence prediction\n",
    "C = 6\n",
    "sample_size = 3000\n",
    "seq_pred = viterbi(x_standard[:sample_size,:], 4, log_transition_train, mu, sigma_diag, C)\n",
    "# Shifting the index of 1\n",
    "seq_pred += 1\n",
    "print 'ACCURACY train: {}'.format(compute_accuracy(seq_pred, y_train[:sample_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY test: 0.768917543264\n",
      "CPU times: user 7.64 s, sys: 97.1 ms, total: 7.73 s\n",
      "Wall time: 8.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_sub_test_standard = standardize(x_sub_test)\n",
    "seq_pred_test = viterbi(x_sub_test_standard[:sample_size,:], 4, log_transition_train, mu, sigma_diag, C)\n",
    "seq_pred_test += 1\n",
    "print 'ACCURACY test: {}'.format(compute_accuracy(seq_pred_test, y_test[:sample_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print seq_pred_test[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample + pyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We use here the model fited by PyMc\n",
    "means = []\n",
    "covs = []\n",
    "\n",
    "with h5py.File('../HAR/means_covs.hdf5', \"r\") as f:\n",
    "    for k in xrange(6):\n",
    "        means.append(np.array(f.get('mu_{}'.format(k+1))))\n",
    "        # Pymc provides tau, cov = (tau)^{-1}\n",
    "        covs.append(np.linalg.pinv(np.array(f.get('cov_{}'.format(k+1)))))\n",
    "means = np.array(means)\n",
    "covs = np.array(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 16 µs\n",
      "ACCURACY train: 0.278\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sequence prediction\n",
    "C = 6\n",
    "sample_size = 1000\n",
    "seq_pred = viterbi(x_standard[:sample_size,:], 4, log_transition_train, means, covs, C)\n",
    "# Shifting the index of 1\n",
    "seq_pred += 1\n",
    "print 'ACCURACY train: {}'.format(compute_accuracy(seq_pred, y_train[:sample_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Backward algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0364018687618\n",
      "-3.31313516605\n"
     ]
    }
   ],
   "source": [
    "print(compute_B(x[0], mu, sigma_diag, 4))\n",
    "print(compute_logB(x[0], mu, sigma_diag, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward(x, init, end, log_transition, mu, sigma_diag):\n",
    "    '''\n",
    "    Compute log(p(X|lambda)) with lambda the HMM parameters\n",
    "    (here transition, mu, sigma_diag)\n",
    "    alpha[t, j] = p(x_1, ... x_t, S(t) = s_j|lambda)\n",
    "    NB:\n",
    "        alpha[0, :] used only as initialization\n",
    "        log-sum-exp trick used\n",
    "    '''\n",
    "    C = mu.shape[0]\n",
    "    T = x.shape[0]\n",
    "    # Initialization\n",
    "    alpha = np.zeros((T+1, C))\n",
    "    alpha[0, init] = 1\n",
    "    alpha[0,:] = np.log(alpha[0,:])\n",
    "    \n",
    "    # Recursion\n",
    "    for t in xrange(1, T-1):\n",
    "        for j in xrange(C):\n",
    "            b_t_j = compute_logB(x[t-1], mu, sigma_diag, j)\n",
    "            a = b_t_j + alpha[t-1, :] + log_transition[j,:]\n",
    "            # log-sum-exp trick\n",
    "            max_a = np.max(a)\n",
    "            alpha[t, j] = max_a + np.log(np.sum(np.exp(a - max_a)))\n",
    "    \n",
    "    # Termination\n",
    "    b_t_j = compute_logB(x[T-1], mu, sigma_diag, end)\n",
    "    a = b_t_j + alpha[T, :] + log_transition[:,end]\n",
    "    max_a = np.max(a)\n",
    "    alpha[T, end] = max_a + np.log(np.sum(np.exp(a - max_a)))\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def backward(x, init, end, log_transition, mu, sigma_diag):\n",
    "    '''\n",
    "    Compute the log backward probabilities.\n",
    "    beta[t, j] = p(x_{t+1}, ..., x_{T}| S(t) = s_j, lambda)\n",
    "    '''\n",
    "    C = mu.shape[0]\n",
    "    T = x.shape[0]\n",
    "    # Initialization\n",
    "    beta = np.zeros((T+1, C))\n",
    "    for i in xrange(C):\n",
    "        beta[T, i] = log_transition[end, i]\n",
    "    \n",
    "    # Recursion\n",
    "    for t in xrange(T-1, 0, -1):\n",
    "        for j in xrange(C):\n",
    "            a = beta[t+1, :] + log_transition[j,:]\n",
    "            for i in xrange(C):\n",
    "                b_t1_i = compute_logB(x[t], mu, sigma_diag, i)\n",
    "                a[i] += b_t1_i\n",
    "            max_a = np.max(a)\n",
    "            beta[t, j] = max_a + np.log(np.sum(np.exp(a - max_a))) \n",
    "    \n",
    "    # Termination\n",
    "    a = beta[1, :] + log_transition[:, init]\n",
    "    for i in xrange(C):\n",
    "        b_1_i = compute_logB(x[0], mu, sigma_diag, i)\n",
    "        a[i] += b_t1_i\n",
    "    max_a = np.max(a)\n",
    "    beta[0, init] = max_a + np.log(np.sum(np.exp(a - max_a))) \n",
    "        \n",
    "    return beta\n",
    "\n",
    "def compute_state_probability(alpha, beta, end):\n",
    "    '''\n",
    "    compute state occupation log probability\n",
    "    '''\n",
    "    gamma = alpha + beta\n",
    "    # Normalization\n",
    "    gamma -= alpha[-1, end]\n",
    "    return gamma\n",
    "\n",
    "def compute_state_transition(x, alpha, beta, log_transition, mu, sigma_diag, end):\n",
    "    '''\n",
    "    Compute log(p(S(t) = s_i, S(t+1) = s_j| X, lambda))\n",
    "    '''\n",
    "    T = x.shape[0]\n",
    "    C = mu.shape[0]\n",
    "    psi = np.zeros((T, C, C))\n",
    "    for t in xrange(T):\n",
    "        for j in xrange(C):\n",
    "            b_t_j = compute_logB(x[t], mu, sigma_diag, j)\n",
    "            for i in xrange(C):\n",
    "                psi[t, i, j] = alpha[t, i] + log_transition[j, i] + beta[t+1, j] + b_t_j\n",
    "    \n",
    "    return psi - alpha[-1, end]\n",
    "    \n",
    "    \n",
    "def forward_backward(x, init, end, log_transition, mu, sigma_diag, n_iterations):\n",
    "    '''\n",
    "    EM algorithm to fit an HMM to a sequence of observation.\n",
    "    Take as argnument an initial HMM and returns a finer one.\n",
    "    '''\n",
    "    # E-step: estimate the state occupation probabilities (in LOG)\n",
    "    log_alpha = forward(x, init, end, log_transition, mu, sigma_diag)\n",
    "    log_beta = backward(x, init, end, log_transition, mu, sigma_diag)\n",
    "    log_state_probability = compute_state_probability(alpha, beta, end)\n",
    "    log_state_transition = compute_state_transition(x, alpha, beta, log_transition, mu, sigma_diag, end)\n",
    "    \n",
    "    # M-step: re-estimate HMM parameers\n",
    "    state_probability = np.exp(log_state_probability)\n",
    "    \n",
    "    denom = np.sum(state_probability, axis=0)[np.newaxis, :]\n",
    "    mu = np.dot(state_probability.T, x)/denom\n",
    "    \n",
    "    for j in xrange(C):\n",
    "        diff = x - mu[j]\n",
    "        sigma_diag[:, j] = np.std(np.multiply(np.sqrt(np.abs(state_probability[:,j])), diff), axis=1)\n",
    "    sigma_diag /= denom\n",
    "    \n",
    "    state_transition = np.exp(log_state_transition)\n",
    "    for i in xrange(C):\n",
    "        for j in xrange(C):\n",
    "            log_transition[i, j] = np.log(np.sum(state_transition[:, i, j]))\n",
    "        log_transition[i,:] -= np.sum(state_transition[:, i, :])\n",
    "    \n",
    "    return log_transition, mu, sigma_diag\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03526312, -9.41458649, -9.41458649, -9.41458649, -9.41458649,\n",
       "        -3.37195365],\n",
       "       [-9.28042598, -0.05116572, -2.9870067 , -9.28042598, -9.28042598,\n",
       "        -9.28042598],\n",
       "       [-3.15421695, -4.24808989, -0.05897258, -9.19684978, -9.19684978,\n",
       "        -9.19684978],\n",
       "       [-9.46234345, -9.46234345, -9.46234345, -0.03439482, -3.41971062,\n",
       "        -7.06444818],\n",
       "       [-9.52850315, -3.55979559, -6.48398071, -9.52850315, -0.03140614,\n",
       "        -9.52850315],\n",
       "       [-9.5522265 , -9.5522265 , -9.5522265 , -3.48611841, -9.5522265 ,\n",
       "        -0.03139126]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_transition_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 300 ms, total: 20.3 s\n",
      "Wall time: 23 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:15: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha = forward(x_standard, 4, 1, log_transition_train, mu, sigma_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.383657281332981"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 528 ms, total: 1min 41s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "beta = backward(x_standard, 4, 1, transition_train, mu, sigma_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,  -2.82130318e+04,   0.00000000e+00],\n",
       "       [ -2.82039979e+04,  -2.82041351e+04,  -2.82041184e+04,\n",
       "         -2.82040964e+04,  -2.82032426e+04,  -2.82041383e+04],\n",
       "       [ -2.82045037e+04,  -2.82046236e+04,  -2.82046084e+04,\n",
       "         -2.82045847e+04,  -2.82037219e+04,  -2.82046266e+04],\n",
       "       ..., \n",
       "       [ -3.46044252e+00,  -3.92440437e+00,  -3.86841289e+00,\n",
       "         -3.99421940e+00,  -3.50917685e+00,  -4.01322867e+00],\n",
       "       [ -3.55068100e+00,  -2.93135336e+00,  -3.09425013e+00,\n",
       "         -3.58311740e+00,  -3.56977062e+00,  -3.58753772e+00],\n",
       "       [  9.32314003e-05,   9.50121201e-01,   5.04381876e-02,\n",
       "          9.32314003e-05,   9.32314003e-05,   9.32314003e-05]])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 342 µs, sys: 560 µs, total: 902 µs\n",
      "Wall time: 523 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_state_probability = compute_state_probability(alpha, beta, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[            -inf,             -inf,             -inf,\n",
       "                    -inf,   1.07081128e+04,             -inf],\n",
       "       [  1.07064931e+04,   1.07021708e+04,   1.07041988e+04,\n",
       "          1.07091643e+04,   1.07170520e+04,   1.06961106e+04],\n",
       "       [  1.07048689e+04,   1.07005865e+04,   1.07024716e+04,\n",
       "          1.07079809e+04,   1.07160041e+04,   1.06950842e+04],\n",
       "       ..., \n",
       "       [  4.08235136e-01,   5.08212972e+00,   5.24975955e+00,\n",
       "         -1.48447212e+00,   7.08567891e+00,  -1.22325067e+01],\n",
       "       [ -8.73097611e-01,   2.11465479e+00,   2.61131359e+00,\n",
       "         -2.42437828e+00,   5.63969140e+00,  -1.47016760e+01],\n",
       "       [ -4.65002938e+00,   9.50121201e-01,   1.15931027e+00,\n",
       "         -3.66143284e+00,  -1.74864808e+00,  -1.35500344e+01]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_state_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0136295297\n",
      "10690.6640337\n"
     ]
    }
   ],
   "source": [
    "t = 3\n",
    "i=1\n",
    "j=1\n",
    "b_t_j = compute_logB(x[t], mu, sigma_diag, j)\n",
    "print b_t_j\n",
    "print(alpha[1, i] + log_transition_train[j, i] + beta[t+1, j] + b_t_j - alpha[-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 s, sys: 114 ms, total: 17.2 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_state_transition = compute_state_transition(x_standard, alpha, beta, log_transition_train, mu, sigma_diag, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 6, 6)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_state_transition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_alpha = alpha\n",
    "log_beta = beta\n",
    "\n",
    "# M-step: re-estimate HMM parameers\n",
    "state_probability = np.exp(log_state_probability)\n",
    "\n",
    "denom = np.sum(state_probability, axis=0)[np.newaxis, :]\n",
    "mu = np.dot(state_probability.T, x_standard)/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:5: RuntimeWarning: overflow encountered in exp\n",
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:15: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'log_transition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-425-ffb054f66fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlog_transition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_transition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mlog_transition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_transition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_transition' is not defined"
     ]
    }
   ],
   "source": [
    "for j in xrange(C):\n",
    "    diff = x_standard - mu[j]\n",
    "    sigma_diag[:, j] = np.std(np.sqrt(np.abs(state_probability[:,j]))[:, np.newaxis]*diff, axis=0)\n",
    "sigma_diag /= denom\n",
    "\n",
    "state_transition = np.exp(log_state_transition)\n",
    "for i in xrange(C):\n",
    "    for j in xrange(C):\n",
    "        log_transition[i, j] = np.log(np.sum(state_transition[:, i, j]))\n",
    "    log_transition[i,:] -= np.sum(state_transition[:, i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.sqrt(np.abs(state_probability[:,0]))[:, np.newaxis]*diff, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28213.031783239847"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.383657281332981"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
