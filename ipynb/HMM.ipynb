{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "with h5py.File('../HAR/preprocessed.hdf5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    y_train = np.array(hf.get('y_train'))\n",
    "    s_train = np.array(hf.get('s_train'))\n",
    "    x_test = np.array(hf.get('x_test'))\n",
    "    y_test = np.array(hf.get('y_test'))\n",
    "    s_test = np.array(hf.get('s_test'))\n",
    "    x_train_with_past = np.array(hf.get('x_train_with_past'))\n",
    "    y_train_with_past = np.array(hf.get('y_train_with_past'))\n",
    "    x_test_with_past = np.array(hf.get('x_test_with_past'))\n",
    "    y_test_with_past = np.array(hf.get('y_test_with_past'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infering HMM parameters using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning a one component Gaussian over all the features\n",
    "def compute_transition(y, alpha=0.1):\n",
    "    '''\n",
    "    Compute the transition matrice.\n",
    "    Rows: states to\n",
    "    cols: states from\n",
    "    States are indexed starting from 1\n",
    "    '''\n",
    "    num_state = np.max(y)\n",
    "    transition = alpha*np.ones((num_state, num_state))\n",
    "    for i in xrange(y.shape[0]-1):\n",
    "        transition[y[i+1]-1, y[i]-1] += 1\n",
    "    # Normalisation (column should be normalized)\n",
    "    transition /= np.sum(transition, axis=1)[:, np.newaxis]\n",
    "    return transition\n",
    "\n",
    "def compute_emission(x, y):\n",
    "    '''\n",
    "    Compute the parameters of the gaussian distribution\n",
    "    of the emission given each state.\n",
    "    We assume each emission distribution is independent,\n",
    "    the covariance matrix is diagonal then.\n",
    "    States are indexed starting from 1\n",
    "    '''\n",
    "    num_state = np.max(y)\n",
    "    \n",
    "    sigma_diag = np.zeros((num_state, x.shape[1]))\n",
    "    mu = np.zeros((num_state, x.shape[1]))\n",
    "    for s in xrange(num_state):\n",
    "        x_s = x[(y == s+1), :]\n",
    "        # Computing mu_s\n",
    "        mu[s] = np.mean(x_s, axis=0)\n",
    "        # Computing sigma_s (by column)\n",
    "        sigma_diag[s] = np.std(x_s, axis=0)\n",
    "\n",
    "    return mu, sigma_diag\n",
    "\n",
    "def compute_logscore(data, log_transition, mu, sigma_diag, C):\n",
    "    y = np.zeros((C, C))\n",
    "    for j in xrange(C):\n",
    "        y[j, :] = compute_logB(data, mu, sigma_diag, j)\n",
    "\n",
    "    return y + log_transition\n",
    "\n",
    "def compute_logscore_pymc(data, log_transition, means, cov, C):\n",
    "    y = np.zeros((C, C))\n",
    "    for j in xrange(C):\n",
    "        y[j, :] = scipy.stats.multivariate_normal.logpdf(data, mean=means[j], cov=covs[j])\n",
    "    return y + log_transition\n",
    "\n",
    "def viterbi(inputs, init, log_transition, mu, sigma_diag, C):\n",
    "    '''\n",
    "    Evaluates the highest scoring sequence.\n",
    "    args: \n",
    "        inputs: observation\n",
    "        init: initial probability distribution of the hidden states (C vector)\n",
    "    '''\n",
    "    y = np.zeros((C, C))\n",
    "    initial = np.log(init)\n",
    "\n",
    "    n = inputs.shape[0]\n",
    "    # To store the maxes\n",
    "    max_table = np.zeros((n, C))\n",
    "    backpointer_table = np.zeros((n, C))\n",
    "\n",
    "    # first timestep\n",
    "    # the initial most likely paths are the initial state distribution\n",
    "    state_init = initial + compute_logscore(inputs[0,:], log_transition, mu, sigma_diag, C)\n",
    "    maxes = np.max(state_init, axis=1)\n",
    "    backpointers = np.argmax(state_init, axis=1)\n",
    "    max_table[0, :] = maxes\n",
    "\n",
    "    for i in xrange(1, n):\n",
    "        # COmputing the score\n",
    "        y = compute_logscore(inputs[i, :], log_transition, mu, sigma_diag, C)\n",
    "        scores = y + np.repeat(maxes.reshape(1, C), C, axis=0)\n",
    "\n",
    "        # compute new maxes\n",
    "        maxes = np.max(scores, axis=1)\n",
    "        backpointers = np.argmax(scores, axis=1)\n",
    "\n",
    "        max_table[i, :] = maxes\n",
    "        backpointer_table[i, :] = backpointers\n",
    "\n",
    "    # follow backpointers to recover max path\n",
    "    classes = np.zeros(n)\n",
    "    classes[n-1] = np.argmax(maxes, axis=0)\n",
    "    for i in xrange(n-1, 0, -1):\n",
    "        classes[i-1] = backpointer_table[i, classes[i]]\n",
    "\n",
    "    return classes\n",
    "\n",
    "def standardize(x):\n",
    "    '''\n",
    "    Standardize each column of x\n",
    "    '''\n",
    "    x_std = np.std(x, axis=0)\n",
    "    x_mu = np.mean(x, axis=0)\n",
    "    \n",
    "    return (x - x_mu)/x_std[np.newaxis, :]\n",
    "\n",
    "def compute_accuracy(pred_classes, true_classes):\n",
    "    '''\n",
    "    Compute accuracy\n",
    "    '''\n",
    "    return np.sum(pred_classes == true_classes) /(1.*len(pred_classes))\n",
    "\n",
    "def compute_logB(data_point, mu, sigma_diag, j):\n",
    "    '''\n",
    "    Compute log(p(x|s_j))\n",
    "    '''\n",
    "    return np.sum([scipy.stats.norm.logpdf(d, loc=mu[j, i], scale=sigma_diag[j, i]) for i, d in enumerate(data_point)])\n",
    "\n",
    "def compute_B(data_point, mu, sigma_diag, j):\n",
    "    '''\n",
    "    Compute p(x|s_j)\n",
    "    '''\n",
    "    return np.prod([scipy.stats.norm.pdf(d, loc=mu[j, i], scale=sigma_diag[j, i]) for i, d in enumerate(data_point)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 18)\n"
     ]
    }
   ],
   "source": [
    "# We retain 6 features (known to be independent)\n",
    "\n",
    "features = [0, 1, 2, 40, 41, 42, 80, 81, 82, 120, 121, 122] + range(555, 561)\n",
    "x_sub_train = x_train[:, features]\n",
    "x_sub_test = x_test[:, features]\n",
    "print(x_sub_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 18)\n",
      "(6, 6)\n",
      "(6, 18)\n",
      "(6, 18)\n"
     ]
    }
   ],
   "source": [
    "# Learning the HMM\n",
    "\n",
    "# standardization\n",
    "x_standard = standardize(x_sub_train)\n",
    "x_sub_test_standard = standardize(x_sub_test)\n",
    "print(x_standard.shape)\n",
    "\n",
    "# ### TRANSITION\n",
    "transition_train = compute_transition(y_train)\n",
    "log_transition_train = np.log(transition_train)\n",
    "print(transition_train.shape)\n",
    "\n",
    "# ### EMISSION\n",
    "mu, sigma_diag = compute_emission(x_standard, y_train)\n",
    "print(mu.shape)\n",
    "print(sigma_diag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY train: 0.82154515778\n",
      "CPU times: user 54.6 s, sys: 649 ms, total: 55.2 s\n",
      "Wall time: 59.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sequence prediction\n",
    "C = 6\n",
    "sample_size = x_standard.shape[0]\n",
    "# uniform distribution for the inital state\n",
    "initial = 1./C * np.ones(C)\n",
    "seq_pred = viterbi(x_standard[:sample_size,:], initial, log_transition_train, mu, sigma_diag, C)\n",
    "# Shifting the index of 1\n",
    "seq_pred += 1\n",
    "print 'ACCURACY train: {}'.format(compute_accuracy(seq_pred, y_train[:sample_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY test: 0.768917543264\n",
      "CPU times: user 6.79 s, sys: 27.8 ms, total: 6.82 s\n",
      "Wall time: 6.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq_pred_test = viterbi(x_sub_test_standard[:sample_size,:], initial, log_transition_train, mu, sigma_diag, C)\n",
    "seq_pred_test += 1\n",
    "print 'ACCURACY test: {}'.format(compute_accuracy(seq_pred_test, y_test[:sample_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 18)\n"
     ]
    }
   ],
   "source": [
    "# We retain independent features from the train set, manually chosen\n",
    "features = [0, 1, 2, 40, 41, 42, 80, 81, 82, 120, 121, 122] + range(555, 561)\n",
    "x_sub_train = x_train[:, features]\n",
    "x_sub_test = x_test[:, features]\n",
    "print(x_sub_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 18)\n",
      "(6, 6)\n",
      "(6, 18)\n",
      "(6, 18)\n"
     ]
    }
   ],
   "source": [
    "# Learning the HMM\n",
    "\n",
    "# standardization\n",
    "x_standard = standardize(x_sub_train)\n",
    "print(x_standard.shape)\n",
    "\n",
    "# ### TRANSITION\n",
    "transition_train = compute_transition(y_train)\n",
    "log_transition_train = np.log(transition_train)\n",
    "print(transition_train.shape)\n",
    "\n",
    "# ### EMISSION\n",
    "mu, sigma_diag = compute_emission(x_standard, y_train)\n",
    "print(mu.shape)\n",
    "print(sigma_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY train: 0.82154515778\n",
      "CPU times: user 49.1 s, sys: 258 ms, total: 49.4 s\n",
      "Wall time: 50.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sequence prediction\n",
    "C = 6\n",
    "sample_size = x_standard.shape[0]\n",
    "# uniform distribution for the inital state\n",
    "initial = 1./C * np.ones(C)\n",
    "seq_pred = viterbi(x_standard[:sample_size,:], 4, log_transition_train, mu, sigma_diag, C)\n",
    "# Shifting the index of 1\n",
    "seq_pred += 1\n",
    "print 'ACCURACY train: {}'.format(compute_accuracy(seq_pred, y_train[:sample_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY test: 0.771971496437\n",
      "CPU times: user 19.4 s, sys: 74.5 ms, total: 19.4 s\n",
      "Wall time: 19.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_sub_test_standard = standardize(x_sub_test)\n",
    "seq_pred_test = viterbi(x_sub_test_standard[:sample_size,:], 4, log_transition_train, mu, sigma_diag, C)\n",
    "seq_pred_test += 1\n",
    "print 'ACCURACY test: {}'.format(compute_accuracy(seq_pred_test, y_test[:sample_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Backward algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented the forward backward algorithm but when fitted on the test set the results were lower than the HMM inferred from the train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward(x, init, end, log_transition, mu, sigma_diag):\n",
    "    '''\n",
    "    args:\n",
    "        x: observation sequence\n",
    "        init: hidden state of the initialisation (assumed known)\n",
    "        end: hidden state of the termination (assumed known)\n",
    "        log_transition: log probability of the transition\n",
    "        mu, sigma_diag: parameters for the 1d gaussian distribution\n",
    "                        of the continous emission\n",
    "    \n",
    "    Compute log(p(X|lambda)) with lambda the HMM parameters\n",
    "    (here transition, mu, sigma_diag)\n",
    "    alpha[t, j] = p(x_1, ... x_t, S(t) = s_j|lambda)\n",
    "    NB:\n",
    "        alpha[0, :] used only as initialization\n",
    "        log-sum-exp trick used\n",
    "    '''\n",
    "    C = mu.shape[0]\n",
    "    T = x.shape[0]\n",
    "    \n",
    "    # Initialization\n",
    "    alpha = np.zeros((T, C))\n",
    "    alpha[0, init] = 1\n",
    "    alpha[0,:] = np.log(alpha[0,:])\n",
    "    \n",
    "    # Recursion\n",
    "    for t in xrange(1, T):\n",
    "        \n",
    "        for j in xrange(C):\n",
    "            # Compute log p(S(t)|x_1, ..., x_{t-1})\n",
    "            a = alpha[t-1, :] + log_transition[j,:]\n",
    "            # Compute log evidence at time t in [1, T], x index shifted of 1\n",
    "            b_t_j = compute_logB(x[t], mu, sigma_diag, j)\n",
    "            a += b_t_j\n",
    "            # log-sum-exp trick\n",
    "            max_a = np.max(a)\n",
    "            alpha[t, j] = max_a + np.log(np.sum(np.exp(a - max_a)))\n",
    "        # Normalization\n",
    "        Z_t = np.sum(np.exp(alpha[t, :]))\n",
    "        alpha[t,:] -= np.log(Z_t) \n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def backward(x, init, end, log_transition, mu, sigma_diag):\n",
    "    '''\n",
    "    Compute the log backward probabilities.\n",
    "    beta[t, j] = p(x_{t+1}, ..., x_{T}| S(t) = s_j, lambda)\n",
    "    '''\n",
    "    C = mu.shape[0]\n",
    "    T = x.shape[0]\n",
    "    # Initialization\n",
    "    beta = np.zeros((T, C))\n",
    "    for i in xrange(C):\n",
    "        #beta[T-1, i] = log_transition[end, i]\n",
    "        beta[T-1, i] = 1./C\n",
    "    \n",
    "    # Recursion\n",
    "    for t in xrange(T-2, -1, -1):\n",
    "        for j in xrange(C):\n",
    "            a = beta[t+1, :] + log_transition[:,j]\n",
    "            for i in xrange(C):\n",
    "                b_t_i = compute_logB(x[t+1], mu, sigma_diag, i)\n",
    "                a[i] += b_t_i\n",
    "            max_a = np.max(a)\n",
    "            beta[t, j] = max_a + np.log(np.sum(np.exp(a - max_a))) \n",
    "        \n",
    "    return beta\n",
    "\n",
    "def compute_state_probability(alpha, beta):\n",
    "    '''\n",
    "    compute state occupation log probability\n",
    "    '''\n",
    "    # Removing the initialization\n",
    "    gamma = alpha + beta\n",
    "    # Normalization with log-sum-exp trick\n",
    "    for t in xrange(gamma.shape[0]):\n",
    "        row_max = np.max(gamma[t, :])\n",
    "        Z_row = row_max + np.log(np.sum(np.exp(gamma[t, :] - row_max)))\n",
    "        gamma[t, :] -= Z_row\n",
    "    return gamma\n",
    "\n",
    "def compute_state_transition(x, alpha, beta, log_transition, mu, sigma_diag):\n",
    "    '''\n",
    "    Compute log(p(S(t) = s_i, S(t+1) = s_j| X, lambda))\n",
    "    output: psi of dim (T-1)*C*C, 2nd coord: i, 3nd coord: j\n",
    "    '''\n",
    "    T = x.shape[0]\n",
    "    C = mu.shape[0]\n",
    "    psi = np.zeros((T-1, C, C))\n",
    "    for t in xrange(T-1):\n",
    "        for j in xrange(C):\n",
    "            b_t_j = compute_logB(x[t+1], mu, sigma_diag, j)\n",
    "            for i in xrange(C):\n",
    "                psi[t, i, j] = alpha[t, i] + log_transition[j, i] + beta[t+1, j] + b_t_j\n",
    "        # Normalization with log sum exp trick\n",
    "        mat_max = np.max(psi[t, :, :])\n",
    "        Z_mat = mat_max + np.log(np.sum(np.exp(psi[t, :, :] - mat_max)))\n",
    "        psi[t, :, :] -= Z_mat\n",
    "    \n",
    "    return psi\n",
    "    \n",
    "    \n",
    "def forward_backward(x, init, end, log_transition, mu, sigma_diag, n_iterations):\n",
    "    '''\n",
    "    EM algorithm to fit an HMM to a sequence of observation.\n",
    "    Take as argnument an initial HMM and returns a finer one.\n",
    "    '''\n",
    "    T = x.shape[0]\n",
    "    C = mu.shape[0]\n",
    "    \n",
    "    # Copying object\n",
    "    mu = mu.copy()\n",
    "    sigma_diag = sigma_diag.copy()\n",
    "    log_transition = log_transition.copy()\n",
    "    \n",
    "    for it in xrange(n_iterations):\n",
    "        # ##### E-step: estimate the state occupation probabilities (in LOG)\n",
    "        log_alpha = forward(x, init, end, log_transition, mu, sigma_diag)\n",
    "        log_beta = backward(x, init, end, log_transition, mu, sigma_diag)\n",
    "        log_state_probability = compute_state_probability(log_alpha, log_beta)\n",
    "        log_state_transition = compute_state_transition(x, log_alpha, log_beta, log_transition, mu, sigma_diag)\n",
    "\n",
    "        # ##### M-step: re-estimate HMM parameers\n",
    "        state_probability = np.exp(log_state_probability)\n",
    "        \n",
    "        # Mu\n",
    "        denom = np.sum(state_probability, axis=0)[np.newaxis, :]\n",
    "        mu = np.dot(state_probability.T, x)/denom\n",
    "    \n",
    "        # Sigma_diag (stands for the standard deviation)\n",
    "        for j in xrange(C):\n",
    "            diff = x - mu[j]\n",
    "            numerator = 0\n",
    "            for t in xrange(T):\n",
    "                numerator += state_probability[t, j]*(diff[t, :])**2\n",
    "            sigma_diag[:, j] = numerator\n",
    "        sigma_diag /= denom\n",
    "        # Standard deviation from the variance\n",
    "        sigma_diag = np.sqrt(sigma_diag)\n",
    "        \n",
    "        # Transition \n",
    "        state_transition = np.exp(log_state_transition)\n",
    "        for j in xrange(C):\n",
    "            for i in xrange(C):\n",
    "                log_transition[i, j] = np.log(np.sum(state_transition[:, i, j]))\n",
    "            # Normalization\n",
    "            log_transition[:,j] -= np.log(np.sum(np.exp(log_transition[:, j])))\n",
    "    \n",
    "    return log_transition, mu, sigma_diag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 1.85 s, total: 2min 36s\n",
      "Wall time: 2min 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:24: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "init = 4\n",
    "end = 1\n",
    "n_iterations = 1\n",
    "log_transition_train_new, mu_new, sigma_diag_new = forward_backward(x_standard, init, end, log_transition_train, mu, sigma_diag, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02522293 -0.00177132  0.0045369  -0.56560315 -0.45669749 -0.16650716]\n",
      " [-0.1787534  -0.21936092 -0.19922794 -0.80040918 -0.69653595  0.23307432]\n",
      " [ 0.1947258   0.03247523  0.05793074 -0.47849408 -0.42016397  0.20147609]\n",
      " [-0.01479045  0.13607265  0.04520951  0.30031038  0.1961177  -0.18645536]\n",
      " [ 0.06840119  0.03853049  0.03198569 -0.5189657  -0.34882962 -0.30448021]\n",
      " [-0.07539678 -0.01592395  0.03482719  1.67087662  1.38497542  0.29390974]]\n",
      "[[  3.20748497e-02   5.11016732e-03   1.80171387e-02  -7.20131386e-01\n",
      "   -3.24760551e-01  -1.46342944e-01]\n",
      " [ -1.02742925e-01  -1.46377109e-01  -1.29941861e-01  -1.05855769e+00\n",
      "   -6.09759127e-01   2.30558421e-01]\n",
      " [  1.19262722e-01  -1.58474141e-02  -8.63224139e-03  -4.54759432e-01\n",
      "   -1.62878405e-01   9.94591678e-02]\n",
      " [  2.12879330e-02   5.27697909e-02  -9.83257621e-03   4.22278167e-01\n",
      "    1.87858896e-01  -1.38103410e-01]\n",
      " [  6.30245742e-02   2.40822329e-02  -4.11865495e-04  -8.12583731e-01\n",
      "   -3.07952790e-01  -4.30835170e-01]\n",
      " [ -1.32907154e-01   8.02623316e-02   1.30801406e-01   2.62375407e+00\n",
      "    1.21749198e+00   3.85263936e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Comparing value\n",
    "print mu\n",
    "print mu_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71640716  0.51146808  0.57251528  0.2204994   0.46464535  0.16410181]\n",
      " [ 1.11010689  0.90720976  1.06258925  0.2658547   0.57818387  0.51386202]\n",
      " [ 1.35294292  0.66268894  0.89404002  0.24217263  0.4707116   0.37867326]\n",
      " [ 0.59754132  0.79416585  0.80001113  0.5011433   0.6398332   0.79073217]\n",
      " [ 0.28594946  0.43716819  0.6298047   0.27047212  0.46420367  0.3867504 ]\n",
      " [ 1.44478089  1.80077441  1.5841213   0.84965169  1.13787962  1.96969504]]\n",
      "[[ 0.71588287  1.18695089  1.28687945  0.36375394  0.11872733  1.53986457]\n",
      " [ 0.49937984  0.90743911  0.69755189  0.50722723  0.27305199  1.91454468]\n",
      " [ 0.55933534  1.12130238  0.949279    0.58216285  0.37517684  1.69698245]\n",
      " [ 0.23399855  0.28648606  0.19847864  0.44642535  0.47212612  1.17082647]\n",
      " [ 0.4687372   0.71436897  0.41550837  0.6507232   0.45286168  0.9379705 ]\n",
      " [ 0.1478589   0.56695283  0.29891633  0.43825587  0.17500975  2.05144979]]\n"
     ]
    }
   ],
   "source": [
    "print sigma_diag\n",
    "print sigma_diag_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03526312 -9.41458649 -9.41458649 -9.41458649 -9.41458649 -3.37195365]\n",
      " [-9.28135786 -0.0520976  -2.98793858 -9.28135786 -9.28135786 -9.28135786]\n",
      " [-3.15421695 -4.24808989 -0.05897258 -9.19684978 -9.19684978 -9.19684978]\n",
      " [-9.46234345 -9.46234345 -9.46234345 -0.03439482 -3.41971062 -7.06444818]\n",
      " [-9.5277754  -3.55906784 -6.48325296 -9.5277754  -0.03067839 -9.5277754 ]\n",
      " [-9.5522265  -9.5522265  -9.5522265  -3.48611841 -9.5522265  -0.03139126]]\n",
      "[[ -0.041809    -7.80833221  -3.00067162 -12.09935587  -8.31564974\n",
      "   -5.89637263]\n",
      " [ -5.87007252  -0.06268429  -4.59823386 -10.84370918  -3.44096132\n",
      "   -6.161124  ]\n",
      " [ -5.48580603  -3.21735932  -0.0646534  -10.46995994  -6.31672206\n",
      "   -7.16918734]\n",
      " [ -7.80561917  -6.46173349  -6.11880653  -0.07136785  -4.81457402\n",
      "   -3.43292002]\n",
      " [ -9.33960255  -4.24460649  -8.48779733  -3.07435083  -0.0468914\n",
      "   -4.32094815]\n",
      " [ -3.39669097  -5.42853082  -7.88220199  -3.78946942  -5.62296144\n",
      "   -0.05256675]]\n"
     ]
    }
   ],
   "source": [
    "print log_transition_train\n",
    "print log_transition_train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check the values obtained from the EM algorithm after 1 iteration are similar to those obtained from the fitting on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY train: 0.481\n",
      "CPU times: user 2.46 s, sys: 17.1 ms, total: 2.48 s\n",
      "Wall time: 2.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sequence prediction after 1 iteration\n",
    "C = 6\n",
    "sample_size = 1000\n",
    "initial = 1./C * np.ones(C)\n",
    "seq_pred = viterbi(x_standard[:sample_size,:], initial, log_transition_train_new, mu_new, sigma_diag_new, C)\n",
    "# Shifting the index of 1\n",
    "seq_pred += 1\n",
    "print 'ACCURACY train: {}'.format(compute_accuracy(seq_pred, y_train[:sample_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY test: 0.442\n",
      "CPU times: user 2.54 s, sys: 29.2 ms, total: 2.57 s\n",
      "Wall time: 2.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasdrizard/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sequence prediction after 1 iteration\n",
    "x_sub_test_standard = standardize(x_sub_test)\n",
    "seq_pred_test = viterbi(x_sub_test_standard[:sample_size,:], initial, log_transition_train_new, mu_new, sigma_diag_new, C)\n",
    "seq_pred_test += 1\n",
    "print 'ACCURACY test: {}'.format(compute_accuracy(seq_pred_test, y_test[:sample_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We kept the results from the first approach using HMM, with an accuracy of 77% on the test set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
