{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "from scipy import misc,optimize\n",
    "import marshal\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "with h5py.File('../HAR/preprocessed.hdf5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    y_train = np.array(hf.get('y_train'))\n",
    "    s_train = np.array(hf.get('s_train'))\n",
    "    x_test = np.array(hf.get('x_test'))\n",
    "    y_test = np.array(hf.get('y_test'))\n",
    "    s_test = np.array(hf.get('s_test'))\n",
    "    x_train_with_past = np.array(hf.get('x_train_with_past'))\n",
    "    y_train_with_past = np.array(hf.get('y_train_with_past'))\n",
    "    x_test_with_past = np.array(hf.get('x_test_with_past'))\n",
    "    y_test_with_past = np.array(hf.get('y_test_with_past'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('crf.features.hdf5','r') as crff:\n",
    "    # T x C' x C matrix where:\n",
    "    # T = Number of time steps in the sequence\n",
    "    # C' = Label of previous step\n",
    "    # C = Label of current step\n",
    "    # Note that C' = C = 6\n",
    "    scores_train = np.array(crff.get('scores_train'))\n",
    "    scores_test = np.array(crff.get('scores_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7351L, 6L, 6L)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2946L, 6L, 6L)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 30, 30, 30], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947L, 561L)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352L, 561L)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352L,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert data into a list of sequences of length T\n",
    "def convert(T, slice_features = False):\n",
    "    if slice_features:\n",
    "        x_trn = np.concatenate((x_train[:, :3], x_train[:, 41:44]), axis=1)\n",
    "        x_tst = np.concatenate((x_test [:, :3], x_test [:, 41:44]), axis=1)\n",
    "    else:\n",
    "        x_trn = x_train\n",
    "        x_tst = x_test\n",
    "        \n",
    "    X_train_list = [x_trn  [i*T:(i+1)*T,:] for i in range(x_trn.shape  [0] / T + 1)]\n",
    "    Y_train_list = [y_train[i*T:(i+1)*T]-1 for i in range(y_train.shape[0] / T + 1)]\n",
    "\n",
    "    X_test_list = [x_tst [i*T:(i+1)*T,:] for i in range(x_tst.shape [0] / T + 1)]\n",
    "    Y_test_list = [y_test[i*T:(i+1)*T]-1 for i in range(y_test.shape[0] / T + 1)]\n",
    "\n",
    "    print 'X_train_list = {} sequences of size {}'.format(len(X_train_list), X_train_list[0].shape)\n",
    "    print 'Y_train_list = {} sequences of size {}'.format(len(Y_train_list), Y_train_list[0].shape)\n",
    "    print 'X_test_list  = {} sequences of size {}'.format(len(X_test_list) , X_test_list[0].shape)\n",
    "    print 'Y_test_list  = {} sequences of size {}'.format(len(Y_test_list) , Y_test_list[0].shape)\n",
    "    \n",
    "    return X_train_list, Y_train_list, X_test_list, Y_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRF:\n",
    "    def __init__(self,C,D,sigma=10):\n",
    "        self.v = sigma ** 2\n",
    "        self.v2 = self.v * 2\n",
    "        self.C = C # number of classes\n",
    "        self.D = D # number of features\n",
    "        self.theta  = np.random.randn(1)\n",
    "\n",
    "    def get_features(self, x, ind, training = True):\n",
    "        \"\"\"\n",
    "        x: 2D feature array of size T x D\n",
    "        ind: Index of this sequence in the list\n",
    "        return: 4D array of size T x C x C x D' where dimension:\n",
    "                0 = T or time or sequence index\n",
    "                1 = y' or previous label\n",
    "                2 = y  or current  label\n",
    "                3 = f(y',y,x,i) for each feature i\n",
    "        \"\"\"\n",
    "        result = np.zeros((len(x), self.C, self.C, 1))\n",
    "        score_offset = ind * x.shape[0] - 1\n",
    "        if training:\n",
    "            scores = scores_train\n",
    "        else:\n",
    "            scores = scores_test\n",
    "        for i in range(len(x)):\n",
    "            current_features = x[i]\n",
    "            for j in range(self.C):\n",
    "                for k in range(self.C):\n",
    "                    if i == 0 and ind == 0:\n",
    "                        # first time step so no previous information\n",
    "                        result[i,j,k] = 0\n",
    "                    else:\n",
    "                        result[i,j,k] = scores[score_offset + i, j, k]\n",
    "#                     result[i,j,k, 2 :] = current_features # main features\n",
    "#                     result[i,j,k, 0] = j # features for previous label\n",
    "#                     result[i,j,k, 1] = k # features for current label\n",
    "        return result\n",
    "    \n",
    "    def get_features_labels(self, X_list, Y_list):\n",
    "        observations = [ self.get_features(X_list[i], i) for i in range(len(X_list)) ]\n",
    "        labels = len(Y_list) * [None]\n",
    "        for i in range(len(Y_list)):\n",
    "            # start from end of previous sequence\n",
    "            start = Y_list[i-1][-1] if i > 0 else Y_list[i][0]\n",
    "            end = Y_list[i+1][0] if i < len(Y_list) - 1 else Y_list[i][-1]\n",
    "            labels[i] = np.array([start] + list(Y_list[i]) + [end])\n",
    "        return (observations, labels)\n",
    "        \n",
    "    def regulariser(self,w):\n",
    "        return np.sum(w ** 2) /self.v2\n",
    "\n",
    "    def regulariser_deriv(self,w):\n",
    "        return np.sum(w) / self.v\n",
    "\n",
    "    def log_dot_vm(self, loga, logM):\n",
    "        '''\n",
    "        Add loga to each column of logM then perform logsumexp.\n",
    "        loga: 1D array of size C\n",
    "        logM: 2D array of size C x C\n",
    "        '''\n",
    "        return misc.logsumexp(loga.reshape(loga.shape + (1,)) + logM, axis=0)\n",
    "    \n",
    "    def log_dot_mv(self, logM, logb):\n",
    "        '''\n",
    "        Add logb to each row of logM then perform logsumexp.\n",
    "        logM: 2D array of size C x C\n",
    "        logb: 1D array of size C\n",
    "        '''\n",
    "        return misc.logsumexp(logM + logb.reshape((1,) + logb.shape), axis=1)\n",
    "\n",
    "    def forward(self, M, start=0):\n",
    "        '''\n",
    "        M: 3D matrix of size (T + 1) x C x C\n",
    "        '''\n",
    "        alphas = np.NINF * np.ones((M.shape[0],M.shape[1])) # (T + 1) x C\n",
    "#         alphas = np.zeros((M.shape[0],M.shape[1])) # (T + 1) x C\n",
    "        alpha  = alphas[0] # 1 x C\n",
    "        alpha[start] = 0\n",
    "        for i in range(M.shape[0]-1):\n",
    "            alpha = alphas[i+1] = self.log_dot_vm(alpha, M[i])\n",
    "        alpha = self.log_dot_vm(alpha,M[-1])\n",
    "        return (alphas,alpha)\n",
    "\n",
    "    def backward(self, M, end=-1):\n",
    "        betas = np.zeros((M.shape[0],M.shape[1])) # (T + 1) x C\n",
    "#         betas = np.NINF * np.ones((M.shape[0],M.shape[1])) # (T + 1) x C\n",
    "        beta  = betas[-1]\n",
    "        beta[end] = 0\n",
    "        for i in reversed(range(M.shape[0]-1)):\n",
    "            beta = betas[i] = self.log_dot_mv(M[i+1], beta)\n",
    "        beta = self.log_dot_mv(M[0],beta)\n",
    "        return (betas,beta)\n",
    "\n",
    "    def neg_likelihood_and_deriv(self, x_vec_list, y_vec_list, theta, debug=False):\n",
    "        likelihood = 0\n",
    "        derivative = np.zeros(len(self.theta))\n",
    "        for x_vec,y_vec in zip(x_vec_list,y_vec_list):\n",
    "            \"\"\"\n",
    "            features:       (T + 1) x C x C x D'\n",
    "            M:              (T + 1) x C x C\n",
    "            alphas:         (T + 1) x C\n",
    "            betas:          (T + 1) x C\n",
    "            log_probs:      (T + 1) x C x C \n",
    "            `unnormalised` value here is alpha * M * beta, an unnormalised probability\n",
    "            \"\"\"\n",
    "            features        = x_vec\n",
    "            length          = x_vec.shape[0]\n",
    "            yp_vec_ids      = y_vec[:-2]\n",
    "            y_vec_ids       = y_vec[2:]\n",
    "            log_M           = np.dot(features,theta) # (T + 1) x C x C \n",
    "            log_alphas,last = self.forward(log_M, y_vec[0])\n",
    "            log_betas, zero = self.backward(log_M, y_vec[-1])\n",
    "            time,state      = log_alphas.shape\n",
    "\n",
    "            # reshape\n",
    "            log_alphas1 = log_alphas.reshape(time,state,1)\n",
    "            log_betas1  = log_betas.reshape(time,1,state)\n",
    "            log_Z       = misc.logsumexp(last) # partition function\n",
    "            log_probs   = log_alphas1 + log_M + log_betas1 - log_Z # P(y',y|x)\n",
    "            #                 TxCx1     TxCxC      Tx1xC      1\n",
    "            log_probs   = log_probs.reshape(log_probs.shape+(1,)) # T x C x C x 1\n",
    "            \n",
    "            if debug:\n",
    "                print '**********'\n",
    "                print 'length'\n",
    "                print length\n",
    "                print 'time'\n",
    "                print time\n",
    "                print 'state'\n",
    "                print state\n",
    "                print 'log_M.shape'\n",
    "                print log_M.shape\n",
    "                print 'log_Z'\n",
    "                print log_Z\n",
    "                print 'len(yp_vec_ids)'\n",
    "                print len(yp_vec_ids)\n",
    "                print 'len(y_vec_ids)'\n",
    "                print len(y_vec_ids)\n",
    "                print 'features.shape'\n",
    "                print features.shape\n",
    "                print 'yp_vec_ids'\n",
    "                print yp_vec_ids\n",
    "                print 'y_vec_ids'\n",
    "                print y_vec_ids\n",
    "                print 'log_probs.shape'\n",
    "                print log_probs.shape\n",
    "                print '**********'\n",
    "\n",
    "            \"\"\"\n",
    "            log_probs:    T x C x C x 1\n",
    "            features:     T x C x C x D'\n",
    "            exp_features: D'\n",
    "            emp_features: D'\n",
    "            yp_vec_ids  : T\n",
    "            y_vec_ids   : T\n",
    "            \"\"\"\n",
    "            # Compute expected value of feature functions under empirical distribution\n",
    "            exp_features = np.sum( np.exp(log_probs) * features, axis = (0,1,2) )\n",
    "            # Compute expected value of feature functions under model distribution\n",
    "            emp_features = np.sum( features[ range(length), yp_vec_ids, y_vec_ids ], axis = 0 )\n",
    "            \n",
    "            if debug:\n",
    "                print 'exp_features.shape'\n",
    "                print exp_features.shape\n",
    "                print 'emp_features.shape'\n",
    "                print emp_features.shape\n",
    "                sys.exit(0)\n",
    "\n",
    "            likelihood += np.sum(log_M[ range(length), yp_vec_ids, y_vec_ids ]) - log_Z\n",
    "            derivative += emp_features - exp_features\n",
    "        \n",
    "        print 'likelihood = {}'.format(likelihood - self.regulariser(theta))\n",
    "        return (\n",
    "            - ( likelihood - self.regulariser(theta)), \n",
    "            - ( derivative - self.regulariser_deriv(theta))\n",
    "        )\n",
    "    \n",
    "    def predict(self, x_vec, ind, debug=False):\n",
    "        # small overhead, no copying is done\n",
    "        \"\"\"\n",
    "        features:       len(x_vec+1) x Y' x Y x K\n",
    "        log_potential:  len(x_vec+1) x Y' x Y\n",
    "        argmaxes:       len(x_vec+1) x Y'\n",
    "        \"\"\"\n",
    "        features  = self.get_features(x_vec, ind, training = False)\n",
    "        log_potential = np.dot(features,self.theta)\n",
    "        return self.viterbi_bp(log_potential,len(x_vec),self.C)\n",
    "    \n",
    "    def viterbi_bp(self,log_potential,N,K,debug=False):\n",
    "        g0 = log_potential[0,0]\n",
    "        g  = log_potential[1:]\n",
    "\n",
    "        B = np.ones((N,K), dtype=np.int32) * -1\n",
    "        # compute max-marginals and backtrace matrix\n",
    "        V = g0\n",
    "        for t in xrange(1,N):\n",
    "            U = np.empty(K)\n",
    "            for y in xrange(K):\n",
    "                w = V + g[t-1,:,y]\n",
    "                B[t,y] = b = w.argmax()\n",
    "                U[y] = w[b]\n",
    "            V = U\n",
    "        # extract the best path by brack-tracking\n",
    "        y = V.argmax()\n",
    "        trace = []\n",
    "        for t in reversed(xrange(N)):\n",
    "            trace.append(y)\n",
    "            y = B[t, y]\n",
    "        trace.reverse()\n",
    "        return trace\n",
    "\n",
    "    def train(self,x_seq,y_seq,debug=False):\n",
    "        '''\n",
    "        x_seq: List of 2D feature array of size T x D\n",
    "        y_seq: List of 1D label array of size T\n",
    "        '''\n",
    "        X,Y = self.get_features_labels(x_seq,y_seq)\n",
    "        l = lambda theta: self.neg_likelihood_and_deriv(X,Y,theta,debug)\n",
    "        val = optimize.fmin_l_bfgs_b(l,self.theta)\n",
    "        if debug: print val\n",
    "        self.theta,_,_  = val\n",
    "        return self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_list = 74 sequences of size (100L, 6L)\n",
      "Y_train_list = 74 sequences of size (100L,)\n",
      "X_test_list  = 30 sequences of size (100L, 6L)\n",
      "Y_test_list  = 30 sequences of size (100L,)\n",
      "C = 6, D = 6\n",
      "likelihood = -8572.87584207\n",
      "likelihood = -2968.88758009\n",
      "likelihood = -2851.71819384\n",
      "likelihood = -2476.82378582\n",
      "likelihood = -2769.06521974\n",
      "likelihood = -2397.25435826\n",
      "likelihood = -2396.22165014\n",
      "likelihood = -2396.0502815\n",
      "likelihood = -2396.0500419\n",
      "likelihood = -2396.05004186\n",
      "accuracy = 0.953512046149\n"
     ]
    }
   ],
   "source": [
    "T = 100 # number of time steps in each sequence\n",
    "X_train_list, Y_train_list, X_test_list, Y_test_list = convert(T, slice_features=True)\n",
    "\n",
    "C = 6 # number of classes\n",
    "D = X_train_list[0].shape[1] # number of features\n",
    "print 'C = {}, D = {}'.format(C,D)\n",
    "crf = CRF(C,D)\n",
    "crf.train(X_train_list, Y_train_list, debug=False)\n",
    "\n",
    "total_correct = 0\n",
    "total_count = 0\n",
    "Y_hat_list = []\n",
    "for i in range(len(X_test_list)):\n",
    "    Y_hat = crf.predict(X_test_list[i], i)\n",
    "    total_correct += np.sum(Y_hat == Y_test_list[i])\n",
    "    total_count += len(Y_test_list[i])\n",
    "    Y_hat_list.append(Y_hat)\n",
    "print 'accuracy = {}'.format(float(total_correct) / total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n",
      "2947\n",
      "5.36\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for t in range(len(X_test_list)):\n",
    "    for i in range(X_test_list[t].shape[0]):\n",
    "        d = X_test_list[t][i].reshape((1,) + X_test_list[t][i].shape) - X_train_list[t]\n",
    "        nl = np.argmin(np.sum(d*d))\n",
    "        if Y_test_list[t][i] == Y_train_list[t][nl]:\n",
    "            correct += 1\n",
    "print correct\n",
    "print x_test.shape[0]\n",
    "print float(correct) / num_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4]\n",
      "[4 4 4]\n",
      "(100L, 6L, 6L, 18L)\n",
      "[[ 0.          0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          1.          0.          0.28858451\n",
      "  -0.02029417 -0.13290514 -0.14083968  0.11537494 -0.98524969]\n",
      " [ 0.          0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          1.          0.          0.27841883\n",
      "  -0.01641057 -0.12352019 -0.14155127  0.10937881 -0.99741134]\n",
      " [ 0.          0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          1.          0.          0.27965306\n",
      "  -0.01946716 -0.11346169 -0.14200984  0.10188392 -0.99957395]]\n",
      "------\n",
      "[ 0.          0.          0.          0.          3.          0.          0.\n",
      "  0.          0.          0.          3.          0.          0.8466564\n",
      " -0.05617189 -0.36988702 -0.42440079  0.32663767 -2.98223498]\n"
     ]
    }
   ],
   "source": [
    "o,l = crf.get_features_labels(X_train_list, Y_train_list)\n",
    "yprev = Y_train_list[0][:3]\n",
    "ycurr = Y_train_list[0][1:4]\n",
    "print yprev\n",
    "print ycurr\n",
    "print o[0].shape\n",
    "oo = o[0][ range(3), yprev, ycurr ]\n",
    "print oo\n",
    "print '------'\n",
    "print np.sum(oo, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y_hat_list[4]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,Y = crf.get_features_labels(X_train_list,Y_train_list)\n",
    "mm = np.dot(X[0], crf.theta)\n",
    "log_alphas,last = crf.forward(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.24268359,  1.20707888,  1.06844954,  1.33170123,  1.57438902,\n",
       "        1.4241703 ,  5.92117355, -1.59983502, -1.54587767, -1.54050549,\n",
       "       -1.71867424, -1.544992  , -0.15878944,  0.11982213, -1.17793511,\n",
       "        1.74592755,  0.46401028, -0.54626748])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100L, 6L, 6L, 18L)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101L,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100L, 6L, 6L)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100L, 6L)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  2.  2.  2.]\n",
      " [ 3.  3.  3.  3.  3.]\n",
      " [ 4.  4.  4.  4.  4.]\n",
      " [ 5.  5.  5.  5.  5.]\n",
      " [ 6.  6.  6.  6.  6.]]\n",
      "[[ 2.  3.  4.  5.  6.]\n",
      " [ 2.  3.  4.  5.  6.]\n",
      " [ 2.  3.  4.  5.  6.]\n",
      " [ 2.  3.  4.  5.  6.]\n",
      " [ 2.  3.  4.  5.  6.]]\n",
      "4.58351893846\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1,6)\n",
    "print x.reshape(x.shape + (1,)) + np.ones((5,5))\n",
    "print x.reshape((1,) + x.shape) + np.ones((5,5))\n",
    "print misc.logsumexp(np.ones((6,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5835189384561099"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.exp(1) * 36)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
