{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "from scipy import misc,optimize\n",
    "import marshal\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "with h5py.File('../HAR/preprocessed.hdf5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    y_train = np.array(hf.get('y_train'))\n",
    "    s_train = np.array(hf.get('s_train'))\n",
    "    x_test = np.array(hf.get('x_test'))\n",
    "    y_test = np.array(hf.get('y_test'))\n",
    "    s_test = np.array(hf.get('s_test'))\n",
    "    x_train_with_past = np.array(hf.get('x_train_with_past'))\n",
    "    y_train_with_past = np.array(hf.get('y_train_with_past'))\n",
    "    x_test_with_past = np.array(hf.get('x_test_with_past'))\n",
    "    y_test_with_past = np.array(hf.get('y_test_with_past'))\n",
    "\n",
    "# Pretrained scores for use in CRF feature functions\n",
    "# These scores were trained using the nn.lua script which contains very similar functions to the ones\n",
    "# in the MEMM iTorch notebook\n",
    "with h5py.File('crf.features.hdf5','r') as crff:\n",
    "    # T x C' x C matrix where:\n",
    "    # T = Number of time steps in the sequence\n",
    "    # C' = Label of previous step\n",
    "    # C = Label of current step\n",
    "    # Note that C' = C = 6\n",
    "    scores_train = np.array(crff.get('scores_train'))\n",
    "    scores_test = np.array(crff.get('scores_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_train.shape\n",
      "(7351L, 6L, 6L)\n",
      "scores_test.shape\n",
      "(2946L, 6L, 6L)\n",
      "s_train\n",
      "[ 1  1  1 ..., 30 30 30]\n",
      "x_test.shape\n",
      "(2947L, 561L)\n",
      "x_train.shape\n",
      "(7352L, 561L)\n",
      "y_train.shape\n",
      "(7352L,)\n"
     ]
    }
   ],
   "source": [
    "print 'scores_train.shape'\n",
    "print scores_train.shape\n",
    "print 'scores_test.shape'\n",
    "print scores_test.shape\n",
    "print 's_train'\n",
    "print s_train\n",
    "print 'x_test.shape'\n",
    "print x_test.shape\n",
    "print 'x_train.shape'\n",
    "print x_train.shape\n",
    "print 'y_train.shape'\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert(T, slice_features = False):\n",
    "    '''\n",
    "    Convert data into a list of sequences of length T\n",
    "    '''\n",
    "    if slice_features:\n",
    "        x_trn = np.concatenate((x_train[:, :3], x_train[:, 41:44]), axis=1)\n",
    "        x_tst = np.concatenate((x_test [:, :3], x_test [:, 41:44]), axis=1)\n",
    "    else:\n",
    "        x_trn = x_train\n",
    "        x_tst = x_test\n",
    "        \n",
    "    X_train_list = [x_trn  [i*T:(i+1)*T,:] for i in range(x_trn.shape  [0] / T + 1)]\n",
    "    Y_train_list = [y_train[i*T:(i+1)*T]-1 for i in range(y_train.shape[0] / T + 1)]\n",
    "\n",
    "    X_test_list = [x_tst [i*T:(i+1)*T,:] for i in range(x_tst.shape [0] / T + 1)]\n",
    "    Y_test_list = [y_test[i*T:(i+1)*T]-1 for i in range(y_test.shape[0] / T + 1)]\n",
    "\n",
    "    print 'X_train_list = {} sequences of size {}'.format(len(X_train_list), X_train_list[0].shape)\n",
    "    print 'Y_train_list = {} sequences of size {}'.format(len(Y_train_list), Y_train_list[0].shape)\n",
    "    print 'X_test_list  = {} sequences of size {}'.format(len(X_test_list) , X_test_list[0].shape)\n",
    "    print 'Y_test_list  = {} sequences of size {}'.format(len(Y_test_list) , Y_test_list[0].shape)\n",
    "    \n",
    "    return X_train_list, Y_train_list, X_test_list, Y_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRF:\n",
    "    def __init__(self,C,sigma=10):\n",
    "        self.v = sigma ** 2\n",
    "        self.v2 = self.v * 2\n",
    "        self.C = C # number of classes\n",
    "        self.theta  = np.random.randn(1)\n",
    "\n",
    "    def get_features(self, x, ind, training = True):\n",
    "        '''\n",
    "        x: 2D feature array of size T x D\n",
    "        ind: Index of this sequence in the list\n",
    "        training: Indicates whether in training or testing mode\n",
    "        return: 4D array of size T x C x C x 1 where dimension:\n",
    "                0 = T or time or sequence index\n",
    "                1 = y' or previous label\n",
    "                2 = y  or current  label\n",
    "                3 = feature\n",
    "        '''\n",
    "        result = np.zeros((len(x), self.C, self.C, 1))\n",
    "        score_offset = ind * x.shape[0] - 1\n",
    "        if training:\n",
    "            scores = scores_train\n",
    "        else:\n",
    "            scores = scores_test\n",
    "        for i in range(len(x)):\n",
    "            current_features = x[i]\n",
    "            for j in range(self.C):\n",
    "                for k in range(self.C):\n",
    "                    if i == 0 and ind == 0:\n",
    "                        # first time step so no previous information\n",
    "                        result[i,j,k] = 0\n",
    "                    else:\n",
    "                        # use pre-trained features\n",
    "                        result[i,j,k] = scores[score_offset + i, j, k]\n",
    "        return result\n",
    "    \n",
    "    def get_features_labels(self, X_list, Y_list):\n",
    "        '''\n",
    "        Get features and labels.\n",
    "        X_list: List of features sequence\n",
    "        Y_list: List of label sequence\n",
    "        '''\n",
    "        observations = [ self.get_features(X_list[i], i) for i in range(len(X_list)) ]\n",
    "        labels = len(Y_list) * [None]\n",
    "        for i in range(len(Y_list)):\n",
    "            # start from end of previous sequence\n",
    "            start = Y_list[i-1][-1] if i > 0 else Y_list[i][0]\n",
    "            end = Y_list[i+1][0] if i < len(Y_list) - 1 else Y_list[i][-1]\n",
    "            labels[i] = np.array([start] + list(Y_list[i]) + [end])\n",
    "        return (observations, labels)\n",
    "        \n",
    "    def regularizer(self,w):\n",
    "        return np.sum(w ** 2) /self.v2\n",
    "\n",
    "    def regularizer_deriv(self,w):\n",
    "        return np.sum(w) / self.v\n",
    "\n",
    "    def log_dot_vm(self, loga, logM):\n",
    "        '''\n",
    "        Add loga to each column of logM then perform logsumexp.\n",
    "        loga: 1D array of size C\n",
    "        logM: 2D array of size C x C\n",
    "        '''\n",
    "        return misc.logsumexp(loga.reshape(loga.shape + (1,)) + logM, axis=0)\n",
    "    \n",
    "    def log_dot_mv(self, logM, logb):\n",
    "        '''\n",
    "        Add logb to each row of logM then perform logsumexp.\n",
    "        logM: 2D array of size C x C\n",
    "        logb: 1D array of size C\n",
    "        '''\n",
    "        return misc.logsumexp(logM + logb.reshape((1,) + logb.shape), axis=1)\n",
    "\n",
    "    def forward(self, M, start=0):\n",
    "        '''\n",
    "        M: 3D matrix of size (T + 1) x C x C\n",
    "        '''\n",
    "        alphas = np.NINF * np.ones((M.shape[0],M.shape[1])) # (T + 1) x C\n",
    "        alpha  = alphas[0] # 1 x C\n",
    "        alpha[start] = 0\n",
    "        for i in range(M.shape[0]-1):\n",
    "            alpha = alphas[i+1] = self.log_dot_vm(alpha, M[i])\n",
    "        alpha = self.log_dot_vm(alpha,M[-1])\n",
    "        return (alphas,alpha)\n",
    "\n",
    "    def backward(self, M, end=-1):\n",
    "        '''\n",
    "        M: 3D matrix of size (T + 1) x C x C\n",
    "        '''\n",
    "        betas = np.zeros((M.shape[0],M.shape[1])) # (T + 1) x C\n",
    "        beta  = betas[-1]\n",
    "        beta[end] = 0\n",
    "        for i in reversed(range(M.shape[0]-1)):\n",
    "            beta = betas[i] = self.log_dot_mv(M[i+1], beta)\n",
    "        beta = self.log_dot_mv(M[0],beta)\n",
    "        return (betas,beta)\n",
    "\n",
    "    def neg_likelihood_and_deriv(self, x_vec_list, y_vec_list, theta, debug=False):\n",
    "        '''\n",
    "        Compute negative log-likelihood and derivative for use in L-BFGS optimizer.\n",
    "        '''\n",
    "        likelihood = 0\n",
    "        derivative = np.zeros(len(self.theta))\n",
    "        for x_vec,y_vec in zip(x_vec_list,y_vec_list):\n",
    "            features        = x_vec # T x C x C x 1\n",
    "            length          = x_vec.shape[0]\n",
    "            yp_vec_ids      = y_vec[:-2]\n",
    "            y_vec_ids       = y_vec[2:]\n",
    "            log_M           = np.dot(features,theta) # T x C x C \n",
    "            log_alphas,last = self.forward(log_M, y_vec[0]) # alphas: T x C\n",
    "            log_betas, zero = self.backward(log_M, y_vec[-1]) # betas: T x C\n",
    "            time,state      = log_alphas.shape\n",
    "\n",
    "            # reshape\n",
    "            log_alphas1 = log_alphas.reshape(time,state,1)\n",
    "            log_betas1  = log_betas.reshape(time,1,state)\n",
    "            log_Z       = misc.logsumexp(last) # partition function\n",
    "            log_probs   = log_alphas1 + log_M + log_betas1 - log_Z # P(y',y|x)\n",
    "            #                 TxCx1     TxCxC      Tx1xC      1\n",
    "            log_probs   = log_probs.reshape(log_probs.shape+(1,)) # T x C x C x 1\n",
    "            \n",
    "            \"\"\"\n",
    "            log_probs:    T x C x C x 1\n",
    "            features:     T x C x C x D'\n",
    "            exp_features: D'\n",
    "            emp_features: D'\n",
    "            yp_vec_ids  : T\n",
    "            y_vec_ids   : T\n",
    "            \"\"\"\n",
    "            # Compute expected value of feature functions under empirical distribution\n",
    "            exp_features = np.sum( np.exp(log_probs) * features, axis = (0,1,2) )\n",
    "            # Compute expected value of feature functions under model distribution\n",
    "            emp_features = np.sum( features[ range(length), yp_vec_ids, y_vec_ids ], axis = 0 )\n",
    "            \n",
    "            likelihood += np.sum(log_M[ range(length), yp_vec_ids, y_vec_ids ]) - log_Z\n",
    "            derivative += emp_features - exp_features\n",
    "        \n",
    "        print 'likelihood = {}'.format(likelihood - self.regularizer(theta))\n",
    "        return (\n",
    "            - ( likelihood - self.regularizer(theta)), \n",
    "            - ( derivative - self.regularizer_deriv(theta))\n",
    "        )\n",
    "    \n",
    "    def predict(self, x_vec, ind, debug=False):\n",
    "        # small overhead, no copying is done\n",
    "        \"\"\"\n",
    "        features:       len(x_vec+1) x Y' x Y x K\n",
    "        log_potential:  len(x_vec+1) x Y' x Y\n",
    "        argmaxes:       len(x_vec+1) x Y'\n",
    "        \"\"\"\n",
    "        features  = self.get_features(x_vec, ind, training = False)\n",
    "        log_potential = np.dot(features,self.theta)\n",
    "        return self.viterbi_bp(log_potential,len(x_vec),self.C)\n",
    "    \n",
    "    def viterbi_bp(self, log_score, N, K, debug=False):\n",
    "        '''\n",
    "        Viterbi with backpointers to find most likely sequence labeling.\n",
    "        '''\n",
    "        g0 = log_score[0,0]\n",
    "        g  = log_score[1:]\n",
    "\n",
    "        B = np.ones((N,K), dtype=np.int32) * -1\n",
    "        # compute max-marginals and backtrace matrix\n",
    "        V = g0\n",
    "        for t in xrange(1,N):\n",
    "            U = np.empty(K)\n",
    "            for y in xrange(K):\n",
    "                w = V + g[t-1,:,y]\n",
    "                B[t,y] = b = w.argmax()\n",
    "                U[y] = w[b]\n",
    "            V = U\n",
    "        # extract the best path by brack-tracking\n",
    "        y = V.argmax()\n",
    "        trace = []\n",
    "        for t in reversed(xrange(N)):\n",
    "            trace.append(y)\n",
    "            y = B[t, y]\n",
    "        trace.reverse()\n",
    "        return trace\n",
    "\n",
    "    def train(self,x_seq,y_seq,debug=False):\n",
    "        '''\n",
    "        x_seq: List of 2D feature array of size T x D\n",
    "        y_seq: List of 1D label array of size T\n",
    "        '''\n",
    "        X,Y = self.get_features_labels(x_seq,y_seq)\n",
    "        l = lambda theta: self.neg_likelihood_and_deriv(X,Y,theta,debug)\n",
    "        val = optimize.fmin_l_bfgs_b(l,self.theta)\n",
    "        if debug: print val\n",
    "        self.theta,_,_  = val\n",
    "        return self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break original time series data into chunks of size $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_list = 74 sequences of size (100L, 561L)\n",
      "Y_train_list = 74 sequences of size (100L,)\n",
      "X_test_list  = 30 sequences of size (100L, 561L)\n",
      "Y_test_list  = 30 sequences of size (100L,)\n",
      "likelihood = -18922.7071363\n",
      "likelihood = -2555.98463968\n",
      "likelihood = -2521.5400147\n",
      "likelihood = -2419.78342679\n",
      "likelihood = -2406.15088929\n",
      "likelihood = -2396.33634711\n",
      "likelihood = -2396.05295878\n",
      "likelihood = -2396.05004282\n",
      "likelihood = -2396.05004186\n",
      "Accuracy = 95.35%\n"
     ]
    }
   ],
   "source": [
    "T = 100 # number of time steps in each sequence\n",
    "X_train_list, Y_train_list, X_test_list, Y_test_list = convert(T)\n",
    "\n",
    "C = 6 # number of classes\n",
    "crf = CRF(C)\n",
    "crf.train(X_train_list, Y_train_list, debug=False)\n",
    "\n",
    "total_correct = 0\n",
    "total_count = 0\n",
    "Y_hat_list = []\n",
    "for i in range(len(X_test_list)):\n",
    "    Y_hat = crf.predict(X_test_list[i], i)\n",
    "    total_correct += np.sum(Y_hat == Y_test_list[i])\n",
    "    total_count += len(Y_test_list[i])\n",
    "    Y_hat_list.append(Y_hat)\n",
    "print 'Accuracy = {0:.2f}%'.format(float(total_correct) * 100 / total_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
