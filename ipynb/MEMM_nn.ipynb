{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'nn'\n",
    "require 'randomkit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define all the necessaru functions:\n",
    "- Train function\n",
    "- An accuracy function\n",
    "- A fonction that outputs the log-score for MEMM computation\n",
    "- A viterbi implementation\n",
    "- An f-score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train_model(train_inputs, train_outputs, test_inputs, test_outputs, model, criterion, eta, nEpochs, batch)\n",
    "    -- Train the model with a SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- eta = 0.01\n",
    "\n",
    "    -- To store the loss\n",
    "    local batch = batch or 16\n",
    "    local loss = torch.zeros(nEpochs)\n",
    "    local av_L = 0\n",
    "    local f = 0\n",
    "    local df_do\n",
    "    local len = train_inputs:size(2)\n",
    "    for i = 1, nEpochs do\n",
    "        -- Display progess\n",
    "        xlua.progress(i, nEpochs)\n",
    "\n",
    "        -- timing the epoch\n",
    "        local timer = torch.Timer()\n",
    "        av_L = 0\n",
    "        \n",
    "        for ii = 1, train_inputs:size(1), batch do\n",
    "            \n",
    "            current_batch_size = math.min(batch,train_inputs:size(1)-ii)\n",
    "            -- reset gradients\n",
    "            model:zeroGradParameters()\n",
    "\n",
    "            -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "            local pred = model:forward(train_inputs:narrow(1, ii, current_batch_size))\n",
    "            -- Average loss computation\n",
    "            f = criterion:forward(pred, train_outputs:narrow(1, ii, current_batch_size))\n",
    "            av_L = av_L + f\n",
    "            \n",
    "            -- Backward pass\n",
    "            df_do = criterion:backward(pred, train_outputs:narrow(1, ii, current_batch_size))\n",
    "            model:backward(train_inputs:narrow(1, ii, current_batch_size), df_do)\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "\n",
    "        loss[i] = av_L/math.floor(train_inputs:size(1)/batch)\n",
    "        acc_test = accuracy(test_inputs, test_outputs, model)\n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('\\n')\n",
    "        print('Average Loss: '.. loss[i])\n",
    "        print('\\n')\n",
    "        print('Accucary on test: '.. acc_test)\n",
    "        print('***************************************************')\n",
    "        if acc_test > 0.99 then\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function accuracy(input, output, model)\n",
    "\n",
    "    local acc = 0.\n",
    "\n",
    "    for i = 1, input:size(1) do\n",
    "        pred = model:forward(input[i])\n",
    "        m, a = pred:view(6,1):max(1)\n",
    "\n",
    "        if a[1][1] == output[i] then\n",
    "            acc = acc + 1.\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return acc/input:size(1)\n",
    "\n",
    "end\n",
    "\n",
    "function compute_logscore(inputs, i, model, C)\n",
    "    local y = torch.zeros(C,C)\n",
    "    local hot_1 = torch.zeros(C)\n",
    "    for j = 1, C do\n",
    "        hot_1:zero()\n",
    "        hot_1[j] = 1\n",
    "        y:narrow(1,j,1):copy(model:forward(torch.cat(hot_1,inputs[i],1)))\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "-- Evaluates the highest scoring sequence:\n",
    "function viterbi(inputs, init, compute_logscore, model, C)\n",
    "    \n",
    "    local y = torch.zeros(C,C)\n",
    "    -- Formating tensors\n",
    "    local initial = torch.zeros(C, 1)\n",
    "    -- initial started with a start of sentence: <t>\n",
    "\n",
    "    initial[{init,1}] = 1\n",
    "    initial:log()\n",
    "\n",
    "    -- number of classes\n",
    "    local n = inputs:size(1)\n",
    "    local max_table = torch.Tensor(n, C)\n",
    "    local backpointer_table = torch.Tensor(n, C)\n",
    "    -- first timestep\n",
    "    -- the initial most likely paths are the initial state distribution\n",
    "    local maxes, backpointers = (initial + compute_logscore(inputs, 1, model, C)[init]):max(2)\n",
    "    max_table[1] = maxes\n",
    "    -- remaining timesteps (\"forwarding\" the maxes)\n",
    "    for i=2,n do\n",
    "        -- precompute edge scores\n",
    "       \n",
    "        y:copy(compute_logscore(inputs, i, model, C))\n",
    "        scores = y:transpose(1,2) + maxes:view(1, C):expand(C, C)\n",
    "\n",
    "        -- compute new maxes \n",
    "        maxes, backpointers = scores:max(2)\n",
    "\n",
    "        -- record\n",
    "        max_table[i] = maxes\n",
    "        backpointer_table[i] = backpointers\n",
    "    end\n",
    "    -- follow backpointers to recover max path\n",
    "    local classes = torch.Tensor(n)\n",
    "    maxes, classes[n] = maxes:max(1)\n",
    "    for i=n,2,-1 do\n",
    "        classes[i-1] = backpointer_table[{i, classes[i]}]\n",
    "    end\n",
    "\n",
    "    return classes\n",
    "end\n",
    "\n",
    "function compute_fscore(predicted_classes, true_classes)\n",
    "    print('here')\n",
    "    local n = predicted_classes:size(1)\n",
    "    local right_pred = 0\n",
    "    local positive_true = 0\n",
    "    local positive_pred = 0\n",
    "    for i=1,n do\n",
    "        if predicted_classes[i] > 1 then\n",
    "            positive_pred = positive_pred + 1\n",
    "        end\n",
    "        if true_classes[i] > 1 then\n",
    "            positive_true = positive_true + 1\n",
    "        end\n",
    "        if (true_classes[i] == predicted_classes[i]) and true_classes[i] > 1 then\n",
    "            right_pred = right_pred + 1\n",
    "        end\n",
    "    end\n",
    "    local precision = right_pred/positive_pred\n",
    "    local recall = right_pred/positive_true\n",
    "    local fscore = 2*precision*recall/(precision+recall)\n",
    "    print('Precision: ' .. precision )\n",
    "    print('Recall: ' ..  recall)\n",
    "    print('F-score: ' ..  fscore)\n",
    "    return fscore\n",
    "end        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../HAR/preprocessed.hdf5','r')\n",
    "f = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = f['x_train_with_past']\n",
    "y_train = f['y_train_with_past']\n",
    "x_test = f['x_test_with_past']\n",
    "y_test = f['y_test_with_past']\n",
    "x_test_withoutpast = f['x_test']\n",
    "y_test_withoutpast = f['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a Multi-Layer Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model:add(nn.Linear(567,600))\n",
    "model:add(nn.Tanh())\n",
    "model:add(nn.Linear(600,300))\n",
    "model:add(nn.Tanh())\n",
    "model:add(nn.Linear(300,6))\n",
    "model:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the weigths uniformly between -0.05 and 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters, gradParameters = model:getParameters()\n",
    "torch.manualSeed(0)\n",
    "randomkit.uniform(parameters,-0.05,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the loss function, i.e. negative log-likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model, and stop when performance on validation/test is aborve 99%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 2.2768828868866\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.99426237201731\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.76646300067889\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 2.4048480987549\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.40304370322274\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.86863543788187\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 2.5992279052734\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.22998727963378\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.95112016293279\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 2.2534151077271\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.14941434914336\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.97454175152749\t\n",
       "***************************************************\t\n",
       "Progress: 5 / 20\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 2.2463109493256\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.10436834244209\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.9837067209776\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 2.5224189758301\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.066432888279924\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98642226748133\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 2.5911090373993\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.041636728998973\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.9877800407332\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 2.2729117870331\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.031995992421462\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98913781398506\t\n",
       "***************************************************\t\n",
       "Progress: 9 / 20\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 2.2532279491425\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.026270128251214\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98913781398506\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 2.221382856369\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.022377649307781\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98913781398506\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 2.3409628868103\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.019502751638916\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 2.3951208591461\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.017273113225178\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n",
       "Progress: 13 / 20\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 2.4190549850464\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.015485348328919\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 2.8025329113007\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.014015566981896\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 3.232125043869\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.012782843053707\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n",
       "Progress: 16 / 20\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 3.6267240047455\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.011731429410472\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 3.1433200836182\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.010822162351313\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 3.136244058609\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.010027245026637\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.98947725729803\t\n",
       "***************************************************\t\n",
       "Progress: 19 / 20\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 3.258013010025\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.0093265053731881\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.989816700611\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 3.4624300003052\t\n",
       "\n",
       "\t\n",
       "Average Loss: 0.0087047845569885\t\n",
       "\n",
       "\t\n",
       "Accucary on test: 0.989816700611\t\n",
       "***************************************************\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = train_model(x_train, y_train, x_test, y_test, model, criterion, 0.01, 20, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We predict a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
